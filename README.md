# Mapping Goodreads data
Jupyter notebook (Colab compatible) written in Python for mapping the origin of books and authors based on Goodreads export files

## Using the notebooks
This repository contains a Jupyter notebook (.ipynb) that generates a world map colour-coded with the number of books and/or read by country, based on a Goodreads export file. It can be opened in Google Colab via button at the top of the file so that the user does not need to download/set up a Python distribution on their own computer. Everything can be done through a virtual IDE (Colab!). I have also included a .csv file containing my own Goodreads reading list in case you want to run it before you try your own.

![Books read](/readme_images/books_read_range_limited.png)

Detailed notes are included such that the notebook can be used by those entirely unfamiliar with Python, the workings can also be modified to suit individual preferences. The basics of running the code are to: make sure you drop your own Goodreads export into the files tab (screenshot of what you should see below, make sure the file_name in the code is the samea as the one you uploaded, and then just run the cells in order (CTRL+ENTER runs a cell) - everything else you should be able to Google.

<img src="/readme_images/screenshot_data_drop.PNG" width="626.6" height="608">

This is a public notebook that is free to use, modify and develop. This code is inspired by a post on r/52books (https://redd.it/tvw05r) and I wrote it partly as a coding exercise, as well as with the aim of widening the scope of my own reading. 

I am no expert programmer, so if you are and want to help out, feel free to fork and send a pull request. Likewise if you are a user coming across issues, don't hesitate to comment.

Otherwise enjoy!
